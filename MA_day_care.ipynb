{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import shapefile as shp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd \n",
    "from geopandas.tools import sjoin # Requires build from github for correct version\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "import os\n",
    "import pysal as ps\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "DATA_DIR = 'data/'\n",
    "FIGURE_DIR = 'plots/'\n",
    "\n",
    "SHAPE_FILE = 'CENSUS2010TOWNS_SHP/CENSUS2010TOWNS_POLY.shp'\n",
    "CHILD_CARE_DATA = 'data/child_care_data1.csv'\n",
    "CHILD_LAT = 'Latitude'\n",
    "CHILD_LONG = 'Longitude'\n",
    "CENSUS_DATA = 'data/census_data.csv'\n",
    "GEO_COL = 'COUSUBFP10'\n",
    "POINT_PROJECTION = 4326 #Projection for lat/longs\n",
    "GEOMETRY = 'geometry' # Column name for geometery data\n",
    "# Default CRS assuming census tiger tracts with NAD83 projections, found from prior work\n",
    "DEFAULT_CRS = {'datum': 'NAD83','k': 0.999975, 'lat_0': 36.66666666666666,'lon_0': -88.33333333333333,\n",
    " 'no_defs': True,'proj': u'tmerc',u'units': u'us-ft',u'x_0': 300000, u'y_0': 0} \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Main function\n",
    "\n",
    "# Build data tied with geographic boundaries\n",
    "\n",
    "shape_df = gpd.read_file(SHAPE_FILE)\n",
    "if shape_df.crs == {}:\n",
    "    shape_df = gpd.GeoDataFrame(shape_df,crs=DEFAULT_CRS)\n",
    "    \n",
    "shape_df[GEOMETRY] = shape_df[GEOMETRY].to_crs(epsg=POINT_PROJECTION)\n",
    "shape_df = gpd.GeoDataFrame(shape_df,crs=None) #Remove crs so join completes\n",
    "\n",
    "# Create dataframe with childcare information, remove points not in the area or null, join to town data\n",
    "child_df = build_points(CHILD_CARE_DATA,CHILD_LAT,CHILD_LONG)\n",
    "\n",
    "child_df = point_out_of_bounds(child_df,shape_df)\n",
    "child_df = sjoin(child_df,shape_df,how='left')\n",
    "# Get age from initial issue date\n",
    "child_df['age'] = pd.to_datetime(child_df['FirstIssueDate']).apply(lambda x: pd.to_datetime('today').year - x.year) # convert age\n",
    "\n",
    "# Split out financial assitance columns\n",
    "financial_cols = dummy_list_col(child_df,'FinancialAssistance',';')\n",
    "# Run analysis across child care centers\n",
    "child_care_analysis(child_df,financial_cols)\n",
    "\n",
    "# Build town level data and join in relevant data from child care dataset\n",
    "census_df = join_census_files()\n",
    "town_data = pd.merge(census_df,shape_df,left_on=GEO_COL.lower(),right_on=GEO_COL)\n",
    "town_data.index = town_data[GEO_COL]\n",
    "town_data = clean_town_data(town_data, child_df)\n",
    "\n",
    "town_analysis(town_data)\n",
    "town_regression(town_data,'under_10_vs_capacity')\n",
    "state_map(town_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def child_care_analysis(df,financial_cols):\n",
    "    '''\n",
    "    Runs custom analysis on child care data, description statistics and graphing\n",
    "    '''   \n",
    "    \n",
    "    print(\"Center Specific Analysis\")\n",
    "    # Basic statistics on key categories\n",
    "    cols = ['age','Capacity','eMailAddress','MailingZipcode','FaxNumber','ProviderPhone']\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        if df[col].dtype == 'O' or col == 'FaxNumber':\n",
    "            print(round(df[col].count()/len(df[col]),2)*100,\n",
    "                  '% of centers have logged an active', col,'\\n')\n",
    "        else:\n",
    "            print(df[col].describe(),'\\n')\n",
    "            \n",
    "         \n",
    "    # Print information about type\n",
    "    print(\"Center Type\\n\")\n",
    "    print(df['ProgramType'].value_counts(),'\\n')\n",
    "    \n",
    "    # Average number of discounts offered\n",
    "    print(\"Financial Discounts:\")\n",
    "    print(df[financial_cols].sum(axis=1).describe())\n",
    "    print('Discount levels:\\n',df[financial_cols].sum(axis=1).value_counts())\n",
    "        \n",
    "          \n",
    "    # Graph age distribution\n",
    "    \n",
    "    df['age'].hist(bins=20)\n",
    "    plt.title(\"Age Distribution of Child Care Centers\")\n",
    "    plt.xlabel(\"Age of centers in years\")\n",
    "    plt.ylabel(\"Number of liscensed centers\")\n",
    "    plt.savefig(FIGURE_DIR + \"age_distribution.png\")\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "    # graph capacity with cutoff bin at 100\n",
    "    data = df['Capacity'].copy()\n",
    "    cut_off = 100\n",
    "    step = 5\n",
    "    bins = list(range(0,cut_off+step*2,step))\n",
    "    data[data > cut_off] = cut_off+1\n",
    "    data.hist(bins=bins)\n",
    "    plt.title(\"Capacity Distribution of Child Care Centers\")\n",
    "    plt.xlabel(\"Total Capacity\")\n",
    "    plt.ylabel(\"Number of liscensed centers\")\n",
    "    plt.xlim([0,cut_off+step])\n",
    "    plt.xticks(bins,bins[:-2]+[str(cut_off)+'+',''],rotation=90)\n",
    "    plt.savefig(FIGURE_DIR + \"capacity_distribution.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze financial assistance\n",
    "    \n",
    "    \n",
    "    # Get ordered list of types of financial assistance\n",
    "    sorted_df = df[financial_cols].sum().sort_values(ascending=False)\n",
    "    sorted_df = sorted_df[sorted_df > 50] # Drop all assistance less than 50 (<5 types)\n",
    "    \n",
    "    # plot\n",
    "    labels = [x.replace(\"FinancialAssistance_\",'') for x in sorted_df.index]\n",
    "    plt.figure(1, figsize = (12, 8))\n",
    "    plt.axes(aspect = 1)\n",
    "    plt.pie(list(sorted_df),labels=labels,startangle = 0,\n",
    "       labeldistance = 1.4,autopct = lambda x: '{:.0f} '.format(x * sum(sorted_df) / 100,x),pctdistance = 1.2)\n",
    "    \n",
    "    plt.title('Count of discounts offered by centers\\n Offered in 50+ centers')\n",
    "    plt.savefig(FIGURE_DIR + \"discount_types.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def town_analysis(town_data):\n",
    "    print(\"\\nTown Analysis\")\n",
    "    make_binary(town_data,'Capacity',0)\n",
    "    print(\"Towns with no capacity:\" ,sum(town_data['Capacity']==0))\n",
    "    print(\"Counties without centers\\n\")\n",
    "    print(town_data[town_data['Capacity']==0].groupby(['COUNTY']).size().sort_values(ascending=False))\n",
    "    no_cap = town_data.ix[town_data['Capacity_binary']==0]\n",
    "    cap = town_data.ix[town_data['Capacity_binary']==1]\n",
    "\n",
    "    # Capacity comparisons\n",
    "    print(\"\\nNon-white\")\n",
    "    t_test(no_cap['percent_non_white_race'],cap['percent_non_white_race'],'no capacity','capacity')\n",
    "    print(\"\\nWhite\")\n",
    "    t_test(no_cap['percent_white_alone_race'],cap['percent_white_alone_race'],'no capacity','capacity')\n",
    "\n",
    "    print(\"\\nMedian Income - no children\")\n",
    "    t_test(no_cap['total_median_income'],cap['total_median_income'],'no capacity','capacity')\n",
    "\n",
    "    print(\"\\nMedian Income - with children\")\n",
    "    t_test(no_cap['families_with_children_median_income'],cap['families_with_children_median_income'],'no capacity','capacity')\n",
    "\n",
    "    print(\"\\nDensity\")\n",
    "    t_test(no_cap['pop_density'],cap['pop_density'],'no capacity','capacity')\n",
    "\n",
    "    print(\"\\nArea in square miles\")\n",
    "    t_test(no_cap['SQ_MILES'],cap['SQ_MILES'],'no capacity','capacity')\n",
    "    print('\\n',town_data.groupby(['TYPE']).mean()['Capacity_binary'])\n",
    "    \n",
    "    \n",
    "    print('\\n Avg. Pop and % of towns with centers\\n',\n",
    "          town_data.groupby(['COUNTY']).mean()[['total_population_age','Capacity_binary']]\n",
    "          .sort_values('total_population_age',ascending=False))\n",
    "\n",
    "    print('\\nMedian centers in neighboring towns: ')\n",
    "    print('No local capacity:', no_cap['nearby_centers'].median())\n",
    "    print('Has local capacity:',cap['nearby_centers'].median())\n",
    "\n",
    "    print('\\nMedian capacity in neighboring towns: ')\n",
    "    print('No local capacity:', round(no_cap['nearby_capacity'].median(),2))\n",
    "    print('Has local capacity:',round(cap['nearby_capacity'].median(),2))\n",
    "\n",
    "def town_regression(town_df,target_variable):\n",
    "    # Create dummies for type of town\n",
    "    town_type_dummies = pd.get_dummies(town_data['TYPE'])\n",
    "    town_type_cols = [x + '_town_type' for x in town_type_dummies.columns]\n",
    "    town_data[town_type_cols] = town_type_dummies\n",
    "\n",
    "    county_dummies = pd.get_dummies(town_data['COUNTY'])\n",
    "    county_cols = [x + '_County' for x in county_dummies.columns]\n",
    "    town_data[county_cols] = county_dummies\n",
    "\n",
    "    # Convert large #s to thousands\n",
    "    get_in_000s(town_data,'families_with_children_median_income')\n",
    "    get_in_000s(town_data,'total_population_age')\n",
    "    \n",
    "    # Normalize target variable and print standard deviation\n",
    "    normalize(town_data,target_variable)\n",
    "    print(\"Standard Deviation: \\n\",town_data[target_variable].std())\n",
    "\n",
    "    # Convert percentages to whole numbers\n",
    "    town_data['percent_non_white_race_whole_numbers'] = town_data['percent_non_white_race'] * 100\n",
    "    town_data['percent_under_10_whole_numbers'] = town_data['percent_age_under_5_years_age'] + town_data['percent_age_5_to_9_years_age'] * 100\n",
    "    town_data['pop_density_100'] = town_data['pop_density'] / 100 \n",
    "\n",
    "    # Specify input variables for OLS Regression model\n",
    "    x_vars = ['percent_non_white_race_whole_numbers'\n",
    "              ,'families_with_children_median_income_in_000s','total_population_age_in_000s',\n",
    "              'SQ_MILES','percent_under_10_whole_numbers','pop_density_100']\n",
    "\n",
    "    # Create plots for key variables\n",
    "    for x in x_vars:\n",
    "        plot_vars(town_data,x,target_variable)\n",
    "    \n",
    "    # Plot of target variable\n",
    "    town_data[target_variable].hist(color='r')\n",
    "    plt.title('Distribution of ratios of population/capacity ratios')\n",
    "    plt.xlabel(target_variable + ' in town')\n",
    "    plt.ylabel('Count of towns')\n",
    "    plt.savefig(FIGURE_DIR + 'distribution_of_' + target_variable)\n",
    "    plt.show()\n",
    "\n",
    "    # Run OLS model    \n",
    "    model = sm.OLS(town_data[target_variable + '_normalized'],\n",
    "                   town_data[x_vars + town_type_cols[:-1]+county_cols[:-1]])# Drop one variable to avoid collinearity\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "\n",
    "def state_map(town_data):\n",
    "    '''\n",
    "    Draw state maps examining proportions of hardcoded columns\n",
    "    '''\n",
    "    \n",
    "    cap_col_name = 'under_10_vs_capacity'\n",
    "    cap_title = 'Relative Rankings of Ratios of Eligible Population to Capacity'\n",
    "    cap_color = 'b'\n",
    "    draw_relative_map(cap_col_name,town_data,cap_title,cap_color)\n",
    "\n",
    "    cnt_col_name = 'under_10_vs_center_count'\n",
    "    cnt_title = 'Relative Rankings of Ratios of Eligible Population to # of Centers'\n",
    "    cnt_color = 'g'\n",
    "    draw_relative_map(cnt_col_name,town_data,cnt_title,cnt_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Organizing town data\n",
    "\n",
    "def clean_town_data(town_data, child_df):\n",
    "\n",
    "    center_cnt = child_df.groupby([GEO_COL]).count()['ProgramName'] # count of centers\n",
    "    center_cap = child_df.groupby([GEO_COL]).sum()['Capacity'] # total capacity of centers\n",
    "    town_data = town_data.join(center_cnt)\n",
    "    town_data = town_data.join(center_cap)\n",
    "    \n",
    "\n",
    "    \n",
    "    town_data.rename(columns={'ProgramName':'center_count',\n",
    "                              'total_median_household_income_in_the_past_12_months_in_2014_inflation-adjusted_dollars_median_income'\n",
    "                              :'total_median_income',\n",
    "                             'median_income_dollars;_total_families_families_with_own_children_under_18_years_detailed_income':\n",
    "                             'families_with_children_median_income'},inplace=True)\n",
    "    # Convert income to int\n",
    "    town_data['total_median_income'] = town_data['total_median_income'].astype(int)\n",
    "    \n",
    "    town_data.loc[town_data['families_with_children_median_income']=='-','families_with_children_median_income'] = 0\n",
    "    town_data.loc[town_data['families_with_children_median_income']=='250,000+','families_with_children_median_income'] = 250000\n",
    "    town_data['families_with_children_median_income'] = town_data['families_with_children_median_income'].astype(int)\n",
    "    \n",
    "\n",
    "    # Set towns with no entries in child care data to 0 for capacity and program name\n",
    "    town_data[['Capacity','center_count']] = town_data[['Capacity','center_count']].fillna(0)\n",
    "\n",
    "    # Add additional columns (nearby towns, age counts & proportions and race proportions)\n",
    "    get_nearby_town_info(town_data)\n",
    "    add_age_categories(town_data)\n",
    "    add_age_proportion_columns(town_data)\n",
    "    add_race_percentages(town_data)\n",
    "    town_data['pop_density'] = town_data['total_population_age'].divide(town_data['SQ_MILES'])\n",
    "    \n",
    "    return town_data\n",
    "\n",
    "def get_nearby_town_info(town_data):\n",
    "    # Adds capacity and count of centers in nearby towns using neighbor calculation from pysal library\n",
    "    num_centers = []\n",
    "    capacity = []\n",
    "    w = ps.weights.user.queen_from_shapefile(SHAPE_FILE,idVariable=GEO_COL)\n",
    "    for town_id in town_data.index:\n",
    "\n",
    "        neighbors = w.neighbors[town_id]\n",
    "\n",
    "        # Get sum total of centers and capacity in neighboring towns\n",
    "        capacity.append(int(town_data.ix[neighbors,['Capacity']].sum()))\n",
    "        num_centers.append(int(town_data.ix[neighbors,['center_count']].sum()))\n",
    "    \n",
    "    town_data['nearby_capacity'] = capacity\n",
    "    town_data['nearby_centers'] = num_centers\n",
    "    \n",
    "def add_age_proportion_columns(town_data):\n",
    "    \n",
    "    # rename proportion columns and created consolidated columns\n",
    "    divide_cols = {'under_5':['total_age_under_5_years_age'],'5_to_9':['total_age_5_to_9_years_age'],\n",
    "                   '10_to_14':['total_age_10_to_14_years_age'],\n",
    "                   'under_10':['total_age_under_5_years_age','total_age_5_to_9_years_age']}\n",
    "\n",
    "\n",
    "    for numerator in  ['Capacity','center_count']:\n",
    "        for key, value in divide_cols.items():\n",
    "            \n",
    "            # add custom total column where columns are being summed\n",
    "            if len(value) > 1:\n",
    "                town_data[key+'_total'] = town_data[value].sum(axis=1)\n",
    "\n",
    "            town_data[key + '_vs_' + numerator.lower()] = town_data[numerator].divide(town_data[value].sum(axis=1))\n",
    "            town_data[key + '_vs_' + numerator.lower()].fillna(0,inplace=True)\n",
    "\n",
    "def add_age_categories(town_data):\n",
    "    '''\n",
    "    Adds full counts of age based on given percents\n",
    "    '''\n",
    "    \n",
    "    town_data.rename(columns={'total_total_population_age':'total_population_age'},inplace=True)\n",
    "    age_categories = [x for x in town_data.columns.tolist() if ('total_age' in x) or ('selected_age' in x)]\n",
    "    \n",
    "    # Convert to percent\n",
    "    percent_age_categories = [x.replace('total_','percent_') for x in age_categories]\n",
    "    town_data[percent_age_categories] = (town_data[age_categories].astype(float) / 100)\n",
    "    \n",
    "    # Get population totals \n",
    "    town_data[age_categories] = town_data[percent_age_categories].multiply(town_data['total_population_age'],axis=0)\n",
    "\n",
    "def add_race_percentages(town_data):\n",
    "    '''\n",
    "    Calculates percentage of race as a total of whole\n",
    "    '''\n",
    "                         \n",
    "    town_data.rename(columns={'total__race':'total_race'},inplace=True)\n",
    "    race_categories = [x for x in town_data.columns.tolist() if ('_race' in x) and ('income' not in x)]\n",
    "    race_categories.remove('total_race')\n",
    "    \n",
    "    # Convert to percent\n",
    "    percent_cols = [x.replace('total','percent') for x in race_categories]\n",
    "    town_data[percent_cols] = town_data[race_categories].divide(town_data['total_race'],axis=0)\n",
    "    \n",
    "    # Calculate the % of non-white only in a town, American Indian and Native Hawaiian are dropped\n",
    "    pct_non_white_race_cols = ['percent_black_or_african_american_alone_race','percent_asian_alone_race','percent_some_other_race_alone_race','percent_two_or_more_races:_race']\n",
    "    town_data['percent_non_white_race'] = town_data[pct_non_white_race_cols].sum(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def t_test(col1,col2,name1,name2):\n",
    "    print(\"Means:\")\n",
    "    print(name1,round(col1.mean(),2))\n",
    "    print(name2,round(col2.mean(),2))\n",
    "    print('Difference = ',round(col1.mean()-col2.mean(),2))\n",
    "    \n",
    "    if stats.ttest_ind(col1,col2)[0] < .05:\n",
    "        print(\"Statisically Significant\")\n",
    "    else:\n",
    "        print(\"Not Statistically Significant\")\n",
    "\n",
    "def normalize(df,col):\n",
    "    \n",
    "    df[col+'_normalized'] = (df[col] - df[col].mean()) / df[col].std()\n",
    "\n",
    "def make_binary(df,col,threshold):\n",
    "    '''\n",
    "    Adds a new binary column in data frame with given threshold\n",
    "    '''\n",
    "    df[col + '_binary'] = df[col] > threshold\n",
    "\n",
    "def get_in_000s(df,col):\n",
    "    df[col + '_in_000s'] = df[col] / 1000\n",
    "    \n",
    "def dummy_list_col(df,split_col,splitter):\n",
    "    # converts a list in a cell to dummies based on the items in that list\n",
    "    atom_cols = []\n",
    "    for col in df[split_col]:\n",
    "        try:\n",
    "            # Split list and add all items that aren't already there, \n",
    "            items = col.split(splitter)\n",
    "            for item in items:\n",
    "                item = item.strip()\n",
    "                inc = False\n",
    "                for atom in atom_cols:\n",
    "                    if item in atom: # String comparison to control for bad splits\n",
    "                        inc = True\n",
    "                        break\n",
    "                if inc:\n",
    "                    pass\n",
    "                else:\n",
    "                    atom_cols.append(item)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    dummies = pd.get_dummies(df[split_col])\n",
    "    \n",
    "    for atom_col in atom_cols:\n",
    "        df[split_col + '_' + atom_col] = dummies[[x for x in dummies.columns if atom_col in x]].sum(axis=1)\n",
    "    \n",
    "    return [split_col + '_' + col for col in atom_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "def plot_vars(df,x_col,y_col):\n",
    "    '''\n",
    "    Creates scatter plot with two variables and makes a historgram of the x variable\n",
    "    '''\n",
    "    title = x_col + '_vs_' + y_col\n",
    "    plt.scatter(df[x_col],df[y_col])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.savefig(FIGURE_DIR + title + '.png')\n",
    "    plt.show()\n",
    "    plt.hist(df[x_col])\n",
    "    plt.title('Distribution of ' + x_col)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel('count')\n",
    "    plt.savefig(FIGURE_DIR + x_col + '_decription.png')\n",
    "    plt.show()\n",
    "    \n",
    "def draw_relative_map(col_name,town_data,title,color):\n",
    "    '''\n",
    "    Makes scaled map of state based on input varibles'''\n",
    "    col = town_data[col_name]\n",
    "    rank_col = col.rank() \n",
    "    col_name = col_name + '_rank'\n",
    "    town_data[col_name] = (rank_col / rank_col.max()).apply(lambda x: 1 - round(x,2))\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "\n",
    "    low_patch = mpl.patches.Patch(fill=False,edgecolor='k', label='Lowest Ratio (10th percentile)')\n",
    "    medium_patch = mpl.patches.Patch(color=color,alpha=.5, label='Median Ratio')\n",
    "    high_patch = mpl.patches.Patch(color=color,alpha=1, label='Highest Ratio (90+ percentile)')\n",
    "    plt.legend(handles=[low_patch,medium_patch,high_patch],loc=3)\n",
    "\n",
    "\n",
    "    for row, shape in enumerate(town_data['geometry']):\n",
    "        alpha = town_data.ix[row,col_name]\n",
    "        try:\n",
    "            x,y = shape.exterior.coords.xy\n",
    "        except:\n",
    "            shape_list = list(shape)\n",
    "            for sub_shape in shape_list:\n",
    "                x,y = sub_shape.exterior.coords.xy\n",
    "                plt.fill(x,y,color=color,alpha=alpha)\n",
    "\n",
    "        plt.fill(x,y,color=color,alpha=alpha)\n",
    "    plt.gcf().set_size_inches(14,8)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(FIGURE_DIR + title + '.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "def get_dataset_name(filename):\n",
    "    # returns name for use in columns of final dataframe\n",
    "    return os.path.basename(filename).replace('.csv','').replace('census_','')\n",
    "    \n",
    "def join_census_files():\n",
    "    # Loops through all files and merges on geoid\n",
    "    cen_files = [DATA_DIR  + x for x in os.listdir(DATA_DIR) if 'census' in x]\n",
    "\n",
    "    df = pd.read_csv(cen_files[0],index_col='Id')\n",
    "    data_set_name = get_dataset_name(cen_files[0])\n",
    "    df.rename(columns=lambda x: x+'_'+data_set_name,inplace=True)    \n",
    "    for filename in cen_files[1:]:\n",
    "        new_df = pd.read_csv(filename,index_col='Id')\n",
    "        data_set_name = get_dataset_name(filename)\n",
    "        new_df.rename(columns=lambda x: x+'_'+data_set_name,inplace=True)\n",
    "        \n",
    "        df = df.join(new_df,how='left')\n",
    "    \n",
    "    return clean_census_data(df)\n",
    "\n",
    "def clean_census_data(census_df):\n",
    "    \n",
    "    # Get town ID out of census provided ID\n",
    "    census_df[GEO_COL] = [x[-5:] for x in census_df.index.tolist()]\n",
    "    \n",
    "    # Drop columns, margin of error, gender, information on imputation\n",
    "    error_cols = [x for x in census_df.columns if 'Margin of Error' in x]\n",
    "    # Gender\n",
    "    gender_cols = [x for x in census_df.columns if ('Female;' in x) or ('Male;' in x)]\n",
    "    # Imputation\n",
    "    impute_cols = [x for x in census_df.columns if 'imputed' in x.lower()]\n",
    "    # ID cols\n",
    "    id_cols = [x for x in census_df.columns if ('Id2' in x) or ('Geography' in x)]\n",
    "    # Drop\n",
    "    census_df.drop(error_cols+gender_cols+impute_cols+id_cols,axis=1,inplace=True)\n",
    "    \n",
    "    # Make names uniform and reduce text\n",
    "    census_df.rename(columns=lambda x: x.replace('Total; Estimate;','total')\n",
    "                     .replace('Estimate; Total: - ','total_').replace('Estimate; Total:','total_').replace('Estimate; ','total_')\n",
    "                     .replace('Median income (dollars); Estimate;','median_income'),inplace=True)\n",
    "    census_df.rename(columns=lambda x:x.replace(' - ','_').replace(' ','_').replace('--','').replace('(','').replace(')','').\n",
    "                     replace(',','').lower(),inplace=True)\n",
    "\n",
    "    \n",
    "    return census_df\n",
    "\n",
    "def build_points(filename,lat,long):\n",
    "    '''\n",
    "    Creates dataframe from file to join to shapefile\n",
    "    '''\n",
    "    point_df = pd.read_csv(filename)\n",
    "    point_df = gpd.GeoDataFrame(point_df)\n",
    "    #Add Points to df\n",
    "    point_list = []\n",
    "    for index, row in point_df.iterrows():\n",
    "        point_list.append(geometry.Point(row[long],row[lat]))\n",
    "    point_df[GEOMETRY] = point_list\n",
    "    return point_df\n",
    "\n",
    "def point_out_of_bounds(point_df, shape_df):\n",
    "    '''\n",
    "    Drops points that aren't in the bounded area or are Null\n",
    "    '''\n",
    "    minx, miny, maxx, maxy = shape_df.total_bounds\n",
    "    #Drop Null & out of range points\n",
    "    return point_df[(point_df[CHILD_LAT] > miny) & (point_df[CHILD_LAT] < maxy) & (point_df[CHILD_LONG] > minx) & (point_df[CHILD_LONG] < maxx)] \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
