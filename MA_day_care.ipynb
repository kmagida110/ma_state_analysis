{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd \n",
    "from geopandas.tools import sjoin # Requires build from github for correct version\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "import os\n",
    "import pysal as ps\n",
    "\n",
    "DATA_DIR = 'data/'\n",
    "FIGURE_DIR = 'plots/'\n",
    "\n",
    "SHAPE_FILE = 'CENSUS2010TOWNS_SHP/CENSUS2010TOWNS_POLY.shp'\n",
    "CHILD_CARE_DATA = 'data/child_care_data1.csv'\n",
    "CHILD_LAT = 'Latitude'\n",
    "CHILD_LONG = 'Longitude'\n",
    "CENSUS_DATA = 'data/census_data.csv'\n",
    "GEO_COL = 'COUSUBFP10'\n",
    "POINT_PROJECTION = 4326 #Projection for lat/longs\n",
    "GEOMETRY = 'geometry' # Column name for geometery data\n",
    "# Default CRS assuming census tiger tracts with NAD83 projections, found from prior work\n",
    "DEFAULT_CRS = {'datum': 'NAD83','k': 0.999975, 'lat_0': 36.66666666666666,'lon_0': -88.33333333333333,\n",
    " 'no_defs': True,'proj': u'tmerc',u'units': u'us-ft',u'x_0': 300000, u'y_0': 0} \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: there are 2 disconnected observations\n",
      "Island ids:  [117, 178]\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "\n",
    "# Build data tied with geographic boundaries\n",
    "\n",
    "shape_df = gpd.read_file(SHAPE_FILE)\n",
    "if shape_df.crs == {}:\n",
    "    shape_df = gpd.GeoDataFrame(shape_df,crs=DEFAULT_CRS)\n",
    "    \n",
    "shape_df[GEOMETRY] = shape_df[GEOMETRY].to_crs(epsg=POINT_PROJECTION)\n",
    "shape_df = gpd.GeoDataFrame(shape_df,crs=None) #Remove crs so join completes\n",
    "\n",
    "# Create dataframe with childcare information, remove points not in the area or null, join to town data\n",
    "child_df = build_points(CHILD_CARE_DATA,CHILD_LAT,CHILD_LONG)\n",
    "\n",
    "child_df = point_out_of_bounds(child_df,shape_df)\n",
    "child_df = sjoin(child_df,shape_df,how='left')\n",
    "# Get age from initial issue date\n",
    "child_df['age'] = pd.to_datetime(child_df['FirstIssueDate']).apply(lambda x: pd.to_datetime('today').year - x.year) # convert age\n",
    "child_care_analysis(child_df)\n",
    "\n",
    "# Build town level data and join in relevant data from child care dataset\n",
    "census_df = join_census_files()\n",
    "town_data = pd.merge(census_df,shape_df,left_on=GEO_COL.lower(),right_on=GEO_COL)\n",
    "town_data.index = town_data[GEO_COL]\n",
    "center_cnt = child_df.groupby([GEO_COL]).count()['ProgramName'] # count of centers\n",
    "center_cap = child_df.groupby([GEO_COL]).sum()['Capacity'] # total capacity of centers\n",
    "town_data = town_data.join(center_cnt)\n",
    "town_data = town_data.join(center_cap)\n",
    "town_data.rename(columns={'ProgramName':'center_count'},inplace=True)\n",
    "\n",
    "# Set towns with no entries in child care data to 0 for capacity and program name\n",
    "town_data[['Capacity','center_count']] = town_data[['Capacity','center_count']].fillna(0)\n",
    "\n",
    "# Get nearby towns based on shared boundary\n",
    "get_nearby_town_info(town_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age_categories = [x for x in town_data.columns.tolist() if 'total_age' in x]\n",
    "\n",
    "town_data[age_categories] = (town_data[age_categories].astype(float) / 100)\n",
    "town_data[age_categories] = town_data[age_categories].multiply(town_data['total_total_population_age'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dummy_list_col(df,split_col,splitter):\n",
    "    # converts a list in a cell to dummies based on the items in that list\n",
    "    atom_cols = []\n",
    "    for col in df[split_col]:\n",
    "        try:\n",
    "            # Split list and add all items that aren't already there, \n",
    "            items = col.split(splitter)\n",
    "            for item in items:\n",
    "                item = item.strip()\n",
    "                inc = False\n",
    "                for atom in atom_cols:\n",
    "                    if item in atom: # String comparison to control for bad splits\n",
    "                        inc = True\n",
    "                        break\n",
    "                if inc:\n",
    "                    pass\n",
    "                else:\n",
    "                    atom_cols.append(item)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    dummies = pd.get_dummies(df[split_col])\n",
    "    \n",
    "    for atom_col in atom_cols:\n",
    "        df[split_col + '_' + atom_col] = dummies[[x for x in dummies.columns if atom_col in x]].sum(axis=1)\n",
    "    \n",
    "    return [split_col + '_' + col for col in atom_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def child_care_analysis(df):\n",
    "    '''\n",
    "    Runs custom analysis on child care data, description statistics and graphing\n",
    "    '''   \n",
    "    \n",
    "    \n",
    "    # Basic statistics on key categories\n",
    "    cols = ['age','Capacity','eMailAddress','MailingZipcode','FaxNumber','ProviderPhone']\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        if df[col].dtype == 'O' or col == 'FaxNumber':\n",
    "            print(round(df[col].count()/len(df[col]),2)*100,\n",
    "                  '% of centers have logged an active', col,'\\n')\n",
    "        else:\n",
    "            print(df[col].describe(),'\\n')\n",
    "            \n",
    "         \n",
    "    # Print information about type\n",
    "    print(\"Center Type\\n\")\n",
    "    print(child_df['ProgramType'].value_counts(),'\\n')\n",
    "    \n",
    "          \n",
    "    # Graph age distribution\n",
    "    \n",
    "    df['age'].hist(bins=20)\n",
    "    plt.title(\"Age Distribution of Child Care Centers\")\n",
    "    plt.xlabel(\"Age of centers in years\")\n",
    "    plt.ylabel(\"Number of liscensed centers\")\n",
    "    plt.savefig(FIGURE_DIR + \"age_distribution.png\")\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "    # graph capacity with cutoff bin at 100\n",
    "    data = df['Capacity'].copy()\n",
    "    cut_off = 100\n",
    "    step = 5\n",
    "    bins = list(range(0,cut_off+step*2,step))\n",
    "    data[data > cut_off] = cut_off+1\n",
    "    data.hist(bins=bins)\n",
    "    plt.title(\"Capacity Distribution of Child Care Centers\")\n",
    "    plt.xlabel(\"Total Capacity\")\n",
    "    plt.ylabel(\"Number of liscensed centers\")\n",
    "    plt.xlim([0,cut_off+step])\n",
    "    plt.xticks(bins,bins[:-2]+[str(cut_off)+'+',''],rotation=90)\n",
    "    plt.savefig(FIGURE_DIR + \"capacity_distribution.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze financial assistance\n",
    "    financial_cols = dummy_list_col(df,'FinancialAssistance',';')\n",
    "    \n",
    "    # Get ordered list of types of financial assistance\n",
    "    sorted_df = df[financial_cols].sum().sort_values(ascending=False)\n",
    "    sorted_df = sorted_df[sorted_df > 50] # Drop all assistance less than 50 (<5 types)\n",
    "    \n",
    "    # plot\n",
    "    labels = [x.replace(\"FinancialAssistance_\",'') for x in sorted_df.index]\n",
    "    plt.figure(1, figsize = (12, 8))\n",
    "    plt.axes(aspect = 1)\n",
    "    plt.pie(list(sorted_df),labels=labels,startangle = 0,\n",
    "       labeldistance = 1.4,autopct = lambda x: '{:.0f} '.format(x * sum(sorted_df) / 100,x),pctdistance = 1.2)\n",
    "    \n",
    "    plt.title('Count of discounts offered by centers\\n Offered in 50+ centers')\n",
    "    plt.savefig(FIGURE_DIR + \"discount_types.png\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dataset_name(filename):\n",
    "    # returns name for use in columns of final dataframe\n",
    "    return os.path.basename(filename).replace('.csv','').replace('census_','')\n",
    "    \n",
    "def join_census_files():\n",
    "    # Loops through all files and merges on geoid\n",
    "    cen_files = [DATA_DIR  + x for x in os.listdir(DATA_DIR) if 'census' in x]\n",
    "\n",
    "    df = pd.read_csv(cen_files[0],index_col='Id')\n",
    "    data_set_name = get_dataset_name(cen_files[0])\n",
    "    df.rename(columns=lambda x: x+'_'+data_set_name,inplace=True)    \n",
    "    for filename in cen_files[1:]:\n",
    "        new_df = pd.read_csv(filename,index_col='Id')\n",
    "        data_set_name = get_dataset_name(filename)\n",
    "        new_df.rename(columns=lambda x: x+'_'+data_set_name,inplace=True)\n",
    "        \n",
    "        df = df.join(new_df,how='left')\n",
    "    \n",
    "    return clean_census_data(df)\n",
    "\n",
    "def clean_census_data(census_df):\n",
    "    \n",
    "    # Get town ID out of census provided ID\n",
    "    census_df[GEO_COL] = [x[-5:] for x in census_df.index.tolist()]\n",
    "    \n",
    "    # Drop columns, margin of error, gender, information on imputation\n",
    "    error_cols = [x for x in census_df.columns if 'Margin of Error' in x]\n",
    "    # Gender\n",
    "    gender_cols = [x for x in census_df.columns if ('Female;' in x) or ('Male;' in x)]\n",
    "    # Imputation\n",
    "    impute_cols = [x for x in census_df.columns if 'imputed' in x.lower()]\n",
    "    # ID cols\n",
    "    id_cols = [x for x in census_df.columns if ('Id2' in x) or ('Geography' in x)]\n",
    "    # Drop\n",
    "    census_df.drop(error_cols+gender_cols+impute_cols+id_cols,axis=1,inplace=True)\n",
    "    \n",
    "    # Make names uniform and reduce text\n",
    "    census_df.rename(columns=lambda x: x.replace('Total; Estimate;','total')\n",
    "                     .replace('Estimate; Total: - ','total_').replace('Estimate; Total:','total_').replace('Estimate; ','total_')\n",
    "                     .replace('Median income (dollars); Estimate;','median_income'),inplace=True)\n",
    "    census_df.rename(columns=lambda x:x.replace(' - ','_').replace(' ','_').replace('--','').replace('(','').replace(')','').\n",
    "                     replace(',','').lower(),inplace=True)\n",
    "\n",
    "    \n",
    "    return census_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nearby_town_info(town_data):\n",
    "    # Adds capacity and count of centers in nearby towns using neighbor calculation from pysal library\n",
    "    num_centers = []\n",
    "    capacity = []\n",
    "    w = ps.weights.user.queen_from_shapefile(SHAPE_FILE,idVariable=GEO_COL)\n",
    "    for town_id in town_data.index:\n",
    "\n",
    "        neighbors = w.neighbors[town_id]\n",
    "\n",
    "        # Get sum total of centers and capacity in neighboring towns\n",
    "        capacity.append(int(town_data.ix[neighbors,['Capacity']].sum()))\n",
    "        num_centers.append(int(town_data.ix[neighbors,['center_count']].sum()))\n",
    "    \n",
    "    town_data['nearby_capacity'] = capacity\n",
    "    town_data['nearby_centers'] = num_centers\n",
    "    \n",
    "def build_points(filename,lat,long):\n",
    "    '''\n",
    "    Creates dataframe from file to join to shapefile\n",
    "    '''\n",
    "    point_df = pd.read_csv(filename)\n",
    "    point_df = gpd.GeoDataFrame(point_df)\n",
    "    #Add Points to df\n",
    "    point_list = []\n",
    "    for index, row in point_df.iterrows():\n",
    "        point_list.append(geometry.Point(row[long],row[lat]))\n",
    "    point_df[GEOMETRY] = point_list\n",
    "    return point_df\n",
    "\n",
    "def point_out_of_bounds(point_df, shape_df):\n",
    "    '''\n",
    "    Drops points that aren't in the bounded area or are Null\n",
    "    '''\n",
    "    minx, miny, maxx, maxy = shape_df.total_bounds\n",
    "    #Drop Null & out of range points\n",
    "    return point_df[(point_df[CHILD_LAT] > miny) & (point_df[CHILD_LAT] < maxy) & (point_df[CHILD_LONG] > minx) & (point_df[CHILD_LONG] < maxx)] \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
